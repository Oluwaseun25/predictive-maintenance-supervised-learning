{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c1efa7-2f53-44c8-bac5-1fa5fabe3009",
   "metadata": {},
   "source": [
    "## Project Description:\n",
    "\n",
    "This notebook focuses on predictive maintenance in industrial settings using machine learning techniques. The objective is to develop a binary classification model capable of predicting machine failures. Leveraging various features such as temperature, rotational speed, torque, and tool wear, the model aims to accurately classify whether a machine is likely to experience failure or not. By employing advanced algorithms and robust evaluation methodologies, the notebook seeks to provide actionable insights for proactive maintenance strategies, ultimately enhancing operational efficiency and reducing downtime in industrial processes.\n",
    "\n",
    "## Project Objective:\n",
    "\n",
    "The primary goal of this notebook is to develop a robust binary classification model for predictive maintenance. The model will leverage historical data on machine performance and failure events to predict whether a machine is likely to fail in the future.\n",
    "\n",
    "Data Preprocessing: Prepare the dataset by cleaning, transforming, and encoding features to ensure compatibility with machine learning algorithms.\n",
    "\n",
    "Feature Engineering: Extract meaningful features and engineer new ones to capture important patterns and relationships in the data, enhancing predictive performance.\n",
    "\n",
    "`Model Training: Implement and fine-tune various machine learning algorithms, including logistic regression, random forest, and gradient boosting, to develop a predictive binary classification model.`\n",
    "\n",
    "`Model Evaluation: Evaluate the performance of the trained models using appropriate metrics such as accuracy, precision, recall, F1 score, and ROC AUC score. Employ cross-validation techniques to ensure robustness and generalization.`\n",
    "\n",
    "Model Deployment: Deploy the best-performing model to production or integrate it into existing systems for real-time prediction of machine failures. Provide recommendations for proactive maintenance actions based on model insights.\n",
    "\n",
    "By achieving these objectives, the notebook aims to empower industrial stakeholders with predictive analytics capabilities, enabling them to anticipate and mitigate potential machine failures, optimize maintenance schedules, and improve overall operational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e943075b-1094-477e-9b3f-9beadecd33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, f1_score, fbeta_score, recall_score, precision_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8d7ca5-45f1-40d5-8938-9399690b4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(r'C:\\Users\\USER\\Documents\\Python Scripts\\Machine learning\\Neural networks\\Predictive Maintenance\\predictive-maintenance-supervised-learning\\scripts')\n",
    "#   # Add the directory containing training and evaluation scripts to Python path\n",
    "\n",
    "# from model_training import fit_models, tune_and_fit\n",
    "# from  model_evaluation import eval_preds,  predict_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc348df9-7cfb-4cab-a560-d40560e07e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data for model training and evaluation(binary)\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Load resampled data for Machine Failure\n",
    "X_res_mf, y_res_mf = joblib.load(r'C:\\Users\\USER\\Documents\\Python Scripts\\Machine learning\\Neural networks\\Predictive Maintenance\\predictive-maintenance-supervised-learning\\data\\resampled_machine_failure.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74984273-f388-485e-b571-629fd5c3e203",
   "metadata": {},
   "source": [
    "## Binary task ¶\n",
    "\n",
    "###  Preliminaries \n",
    "\n",
    "The goal of this section is to find the best model for binary classification of the dataset to predict whether or not there will be Machine Failure. Classification algorithms are part of data mining and use supervised machine learning methods to make predictions about data. In particular, a set of data already divided (”labeled”) into two or more classes of belonging is provided as input thanks to which a classification model is created, which will than be used on new (”unlabeled”) data to assign them to the appropriate class. The starting dataset is usually divided into three groups: the training dataset, i.e. the sample of data used to fit the model, the validation dataset, i.e. the sample of data used to provide an evaluation of a model fit on the training dataset while tuning model hyperparameters and the test dataset, which has the purpose of testing the model. At the beginning of a project a data scientist must make this division and the common ratios used are:\n",
    "\n",
    "70% train, 15% val, 15% test.\n",
    "\n",
    "80% train, 10% val, 10% test.\n",
    "\n",
    "60% train, 20% val, 20% test.\n",
    "\n",
    "In this project we use the ratio (80/10/10) for the split because we test the model for all of these strategies and find that it is the best one. The classification techniques we choose to implement are the following:\n",
    "\n",
    "- Logistic Regression: it estimates the probability of a dependent variable as a function of independent variables. The dependent variable is the output that we are trying to predict while the independent variables or explanatory variables are the factors that we feel could influence the output. For its simplicity and interpretability, we decide to use Logistic Regression as a Benchmark model, a basic model that represents the starting point\n",
    "for comparing the results obtained from other models.\n",
    "\n",
    "- K-nearest neighbors (K-NN): algorithm based on the calculation of the distance between the elements of the dataset. Data is assigned to a certain class if close enough to the other data of the same class. Parameter K represents the number of neighboring data taken into account when assigning classes.\n",
    "\n",
    "- Support Vector Machine: its aim is to find a hyperplane in an N-dimensional space (N—the number of features) that distinctly classifies the data points while maximizing the margin distance, i.e. the distance between data points of both classes.\n",
    "Random Forest: it uses ensemble learning, which is a technique that combines many classifiers to provide solutions to complex problems. Random Forest uses bagging technique: it constructs a multitude of decision trees in parallel, all with the same importance, and the output is the class selected by most trees.\n",
    "\n",
    "- XGBoost: is a gradient-boosted decision tree (GBDT) machine learning library. A Gradient Boosting Decision Tree (GBDT) is a decision tree ensemble learning algorithm similar to Random Forest, from which differs because it uses a boosting technique: it iteratively trains an ensemble of shallow decision trees, with each iteration using the error residuals of the previous model to fit the next model. The final prediction is a weighted sum of all of the tree predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64dc8032-38bc-4a4e-a505-ebf639a1f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-validation-test split\n",
    "X, y = X_res_mf, y_res_mf\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.11, stratify=y_trainval, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262e3f1-22a8-498c-9ef1-ca1f1ba79880",
   "metadata": {},
   "source": [
    "### Feature selection attempts \n",
    "\n",
    "Before going into the training of the models just mentioned we try to perform feature selection, exploiting the considerations  made about the correlation heatmap and the exploratory data analysis: just to remind, it was noticed that the features `\"Process temperature\"` and `\"Air temperature\"` are positively correlated, and `\"Torque\"` and `\"Rotational speed\"` are negatively correlated. From the feature selection we see from the information scores that the product between \"Torque\" and \"Rotational speed\" has more importance than them individually and same can be said about the importance of the product and difference of `\"Process temperature\"` and `\"Air temperature\"` compared to the individual features . For these reasons, completely deleting these columns seems to be a bad choice because important information can be lost but at the same time it is reasonable to see what happens if we combine them taken by pairs. Therefore we proceed to compare the results obtained by fitting the classification models without tuning any parameter on the following datasets:\n",
    "\n",
    "- The original one (without new features)\r",
    "- Tthe one obtained by removing the \"Process temperature\" and \"Air temperature\" columns, replacing them with a column of their produc and differencet\n",
    "- T\n",
    "the one obtained by removing \"Torque\" and \"Rotational speed\", replacing them with a column of their product- Ca comation of ine the previous operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7e919c-1c30-4932-b2a0-2840d447cc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air temperature _K_</th>\n",
       "      <th>Process temperature _K_</th>\n",
       "      <th>Rotational speed _rpm_</th>\n",
       "      <th>Torque _Nm_</th>\n",
       "      <th>Tool wear _min_</th>\n",
       "      <th>temp_product</th>\n",
       "      <th>temp_difference</th>\n",
       "      <th>power_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>1.198103</td>\n",
       "      <td>0.738714</td>\n",
       "      <td>1.901342</td>\n",
       "      <td>-1.553133</td>\n",
       "      <td>0.755412</td>\n",
       "      <td>1.037842</td>\n",
       "      <td>1.298989</td>\n",
       "      <td>-1.364125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>-1.301338</td>\n",
       "      <td>-1.283370</td>\n",
       "      <td>1.171143</td>\n",
       "      <td>-1.412659</td>\n",
       "      <td>-1.569952</td>\n",
       "      <td>-1.332262</td>\n",
       "      <td>-0.698269</td>\n",
       "      <td>-1.438805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-0.951417</td>\n",
       "      <td>-1.215968</td>\n",
       "      <td>-1.097490</td>\n",
       "      <td>0.814846</td>\n",
       "      <td>-0.847204</td>\n",
       "      <td>-1.094564</td>\n",
       "      <td>-0.099092</td>\n",
       "      <td>0.450633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>1.148114</td>\n",
       "      <td>0.738714</td>\n",
       "      <td>-0.924695</td>\n",
       "      <td>1.306503</td>\n",
       "      <td>1.148210</td>\n",
       "      <td>1.007718</td>\n",
       "      <td>1.199126</td>\n",
       "      <td>1.257284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>1.318212</td>\n",
       "      <td>0.603908</td>\n",
       "      <td>-1.145407</td>\n",
       "      <td>1.133277</td>\n",
       "      <td>-1.097286</td>\n",
       "      <td>1.051612</td>\n",
       "      <td>1.738657</td>\n",
       "      <td>0.821230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>0.362873</td>\n",
       "      <td>0.264788</td>\n",
       "      <td>0.329172</td>\n",
       "      <td>-0.714577</td>\n",
       "      <td>1.658028</td>\n",
       "      <td>0.329803</td>\n",
       "      <td>0.332607</td>\n",
       "      <td>-0.755922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6922</th>\n",
       "      <td>0.348293</td>\n",
       "      <td>0.873520</td>\n",
       "      <td>-0.289255</td>\n",
       "      <td>-0.017960</td>\n",
       "      <td>-0.910051</td>\n",
       "      <td>0.583972</td>\n",
       "      <td>-0.598406</td>\n",
       "      <td>-0.076181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>-0.751461</td>\n",
       "      <td>-1.418176</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>-0.690225</td>\n",
       "      <td>0.598293</td>\n",
       "      <td>-1.061903</td>\n",
       "      <td>0.599948</td>\n",
       "      <td>-0.556964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>-0.501517</td>\n",
       "      <td>-0.878954</td>\n",
       "      <td>-0.501068</td>\n",
       "      <td>-0.108264</td>\n",
       "      <td>-1.412833</td>\n",
       "      <td>-0.681217</td>\n",
       "      <td>0.300360</td>\n",
       "      <td>-0.352612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>1.448047</td>\n",
       "      <td>0.671311</td>\n",
       "      <td>1.566900</td>\n",
       "      <td>-1.543099</td>\n",
       "      <td>0.315478</td>\n",
       "      <td>1.159131</td>\n",
       "      <td>1.898166</td>\n",
       "      <td>-1.490539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8206 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Air temperature _K_  Process temperature _K_  Rotational speed _rpm_  \\\n",
       "3829              1.198103                 0.738714                1.901342   \n",
       "335              -1.301338                -1.283370                1.171143   \n",
       "182              -0.951417                -1.215968               -1.097490   \n",
       "3757              1.148114                 0.738714               -0.924695   \n",
       "10002             1.318212                 0.603908               -1.145407   \n",
       "...                    ...                      ...                     ...   \n",
       "10013             0.362873                 0.264788                0.329172   \n",
       "6922              0.348293                 0.873520               -0.289255   \n",
       "1737             -0.751461                -1.418176                0.563573   \n",
       "2591             -0.501517                -0.878954               -0.501068   \n",
       "4594              1.448047                 0.671311                1.566900   \n",
       "\n",
       "       Torque _Nm_  Tool wear _min_  temp_product  temp_difference  \\\n",
       "3829     -1.553133         0.755412      1.037842         1.298989   \n",
       "335      -1.412659        -1.569952     -1.332262        -0.698269   \n",
       "182       0.814846        -0.847204     -1.094564        -0.099092   \n",
       "3757      1.306503         1.148210      1.007718         1.199126   \n",
       "10002     1.133277        -1.097286      1.051612         1.738657   \n",
       "...            ...              ...           ...              ...   \n",
       "10013    -0.714577         1.658028      0.329803         0.332607   \n",
       "6922     -0.017960        -0.910051      0.583972        -0.598406   \n",
       "1737     -0.690225         0.598293     -1.061903         0.599948   \n",
       "2591     -0.108264        -1.412833     -0.681217         0.300360   \n",
       "4594     -1.543099         0.315478      1.159131         1.898166   \n",
       "\n",
       "       power_output  \n",
       "3829      -1.364125  \n",
       "335       -1.438805  \n",
       "182        0.450633  \n",
       "3757       1.257284  \n",
       "10002      0.821230  \n",
       "...             ...  \n",
       "10013     -0.755922  \n",
       "6922      -0.076181  \n",
       "1737      -0.556964  \n",
       "2591      -0.352612  \n",
       "4594      -1.490539  \n",
       "\n",
       "[8206 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b68e39d-d5c9-42ab-966f-be1dd7156e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_training.py\n",
    "def fit_models(clf, clf_str, X_train, X_val, y_train, y_val):\n",
    "    metrics = pd.DataFrame(columns=clf_str)\n",
    "    for model, model_name in zip(clf, clf_str):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        metrics[model_name] = eval_preds(model, X_val, y_val, y_val_pred, 'binary')[1]\n",
    "    return metrics\n",
    "\n",
    "def tune_and_fit(clf, X, y, params, task):\n",
    "    if task == 'binary':\n",
    "        f2_scorer = make_scorer(fbeta_score, pos_label=1, beta=2)\n",
    "        start_time = time.time()\n",
    "        grid_model = GridSearchCV(clf, param_grid=params, cv=5, scoring=f2_scorer)\n",
    "        grid_model.fit(X, y)\n",
    "    elif task == 'multi_class':\n",
    "        f2_scorer = make_scorer(fbeta_score, beta=2, average='weighted')\n",
    "        start_time = time.time()\n",
    "        grid_model = GridSearchCV(clf, param_grid=params, cv=5, scoring=f2_scorer)\n",
    "        grid_model.fit(X, y)\n",
    "\n",
    "    print('Best params:', grid_model.best_params_)\n",
    "    # Print training times\n",
    "    train_time = time.time()-start_time\n",
    "    mins = int(train_time//60)\n",
    "    print('Training time: '+str(mins)+'m '+str(round(train_time-mins*60))+'s')\n",
    "    return grid_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b3f8ac-7b07-4618-8b33-a3ad77557e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_evaluation.py\n",
    "def eval_preds(model, X, y_true, y_pred, task):\n",
    "    if task == 'binary':\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        proba = model.predict_proba(X)[:,1]\n",
    "        acc = accuracy_score(y_true, y_pred)  # Calculate accuracy\n",
    "        auc = roc_auc_score(y_true, proba)\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "        f2 = fbeta_score(y_true, y_pred, pos_label=1, beta=2)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "    elif task == 'multi_class':\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        proba = model.predict_proba(X)\n",
    "        acc = accuracy_score(y_true, y_pred)  # Calculate accuracy\n",
    "        auc = roc_auc_score(y_true, proba, multi_class='ovr', average='weighted')\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        f2 = fbeta_score(y_true, y_pred, beta=2, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "        precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    metrics = pd.Series(data={'ACC':acc, 'AUC':auc, 'F1':f1, 'F2':f2, 'Recall': recall, 'Precision': precision})\n",
    "    metrics = round(metrics,3)\n",
    "    return cm, metrics  # Return confusion matrix and metrics\n",
    "\n",
    "\n",
    "def predict_and_evaluate(fitted_models, X, y_true, clf_str, task):\n",
    "    cm_dict = {key: np.nan for key in clf_str}\n",
    "    metrics = pd.DataFrame(columns=['ACC', 'AUC', 'F1', 'F2', 'Recall', 'Precision'])\n",
    "    y_pred = pd.DataFrame(columns=clf_str)\n",
    "    for fit_model, model_name in zip(fitted_models, clf_str):\n",
    "        y_pred[model_name] = fit_model.predict(X)\n",
    "        if task == 'binary':\n",
    "            cm, scores = eval_preds(fit_model, X, y_true, y_pred[model_name], task)\n",
    "        elif task == 'multi_class':\n",
    "            cm, scores = eval_preds(fit_model, X, y_true, y_pred[model_name], task)\n",
    "        cm_dict[model_name] = cm\n",
    "        metrics.loc[model_name] = scores\n",
    "    return y_pred, cm_dict, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e737e4-cc44-44ff-95ff-aa32a5b1d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over column names\n",
    "for column_name in X_train.columns:\n",
    "    # Check if the column name contains any of the restricted characters\n",
    "    if '[' in column_name or ']' in column_name or '<' in column_name:\n",
    "        print(f\"Column name '{column_name}' contains invalid characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3b592-e522-4e7c-a7b1-e2ee470f4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC(probability=True)\n",
    "rfc = RandomForestClassifier()\n",
    "xgb = XGBClassifier() \n",
    "\n",
    "clf = [lr,knn,svc,rfc,xgb]\n",
    "clf_str = ['LR','KNN','SVC','RFC','XGB'] \n",
    "\n",
    "# Fit on raw train\n",
    "XX_train = X_train.drop(columns=['temp_product','temp_difference','power_output'])\n",
    "XX_val = X_val.drop(columns=['temp_product','temp_difference','power_output'])\n",
    "metrics_0 = fit_models(clf, clf_str, XX_train, XX_val, y_train, y_val)\n",
    "\n",
    "# Fit on temperature product and difference train\n",
    "XX_train = X_train.drop(columns=['Process temperature _K_','Air temperature _K_','power_output'])\n",
    "XX_val = X_val.drop(columns=['Process temperature _K_','Air temperature _K_','power_output'])\n",
    "metrics_1 = fit_models(clf, clf_str, XX_train, XX_val, y_train, y_val)\n",
    "\n",
    "# Fit on power product train\n",
    "XX_train = X_train.drop(columns=['Rotational speed _rpm_','Torque _Nm_','temp_product','temp_difference'])\n",
    "XX_val = X_val.drop(columns=['Rotational speed _rpm_','Torque _Nm_','temp_product','temp_difference'])\n",
    "metrics_2 = fit_models(clf, clf_str, XX_train, XX_val, y_train, y_val)\n",
    "\n",
    "# Fit on both products train\n",
    "# XX_train = X_train.drop(columns=['Process temperature _K_','Air temperature _K_','Rotational speed _rpm_','Torque _Nm_'])\n",
    "# XX_val = X_val.drop(columns=['Process temperature _K_','Air temperature _K_','Rotational speed _rpm_','Torque _Nm_'])\n",
    "metrics_3 = fit_models(clf, clf_str, X_train, X_val, y_train, y_val)\n",
    "\n",
    "# classification metrics barplot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(18,8))\n",
    "fig.suptitle('Classification metrics')\n",
    "for j, model in enumerate(clf_str):\n",
    "    ax = axs[j//3,j-3*(j//3)]\n",
    "    model_metrics = pd.DataFrame(data=[metrics_0[model],metrics_1[model],metrics_2[model],metrics_3[model]])\n",
    "    model_metrics.index = ['Original','Temperature','Power','Both']\n",
    "    model_metrics.transpose().plot(ax=ax, kind='bar', rot=0, )\n",
    "    ax.title.set_text(model)\n",
    "    ax.get_legend().remove()\n",
    "fig.subplots_adjust(top=0.9, left=0.1, right=0.9, bottom=0.12)\n",
    "axs.flatten()[-2].legend(title='Dataset', loc='upper center',\n",
    "                         bbox_to_anchor=(0.5, -0.12), ncol=4, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf19eb-3b67-4b35-ad9f-081d410ab48e",
   "metadata": {},
   "source": [
    "From the results obtained, it is observe that all the models applied to the entire dataset(both), perform better than when they are applied to the ones created by reducing the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2bc104-ee74-4f59-9dd2-2940b4625dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "y_val_lr = lr.predict(X_val)\n",
    "y_test_lr = lr.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "cm_val_lr, metrics_val_lr = eval_preds(lr,X_val,y_val,y_val_lr,'binary')\n",
    "cm_test_lr, metrics_test_lr = eval_preds(lr,X_test,y_test,y_test_lr,'binary')\n",
    "print('Validation set metrics:',metrics_val_lr, sep='\\n')\n",
    "print('Test set metrics:',metrics_test_lr, sep='\\n')\n",
    "\n",
    "cm_labels = ['Not Failure', 'Failure']\n",
    "cm_lr = [cm_val_lr, cm_test_lr]\n",
    "# Show Confusion Matrices\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(8,4))\n",
    "fig.suptitle('LR Confusion Matrices')\n",
    "for j, title in enumerate(['Validation Set', 'Test Set']):\n",
    "    ax = axs[j]\n",
    "    sns.heatmap(ax=ax, data=cm_lr[j], annot=True,\n",
    "              fmt='d', cmap='Blues', cbar=False)\n",
    "    axs[j].title.set_text(title)\n",
    "    axs[j].set_xticklabels(cm_labels)\n",
    "    axs[j].set_yticklabels(cm_labels)\n",
    "plt.show()\n",
    "\n",
    "# Odds for interpretation\n",
    "d = {'feature': X_train.columns, 'odds': np.exp(lr.coef_[0])}\n",
    "odds_df = pd.DataFrame(data=d).sort_values(by='odds', ascending=False)\n",
    "odds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4811736-7491-4e22-b564-c52953654c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing confusion matrix elements for validation data\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_val, y_val_lr).ravel()\n",
    "\n",
    "# Printing confusion matrix elements\n",
    "print(\"True Negatives val:\", tn)\n",
    "print(\"False Positives val:\", fp)\n",
    "print(\"False Negatives val:\", fn)\n",
    "print(\"True Positives val:\", tp)\n",
    "\n",
    "# Accessing confusion matrix elements for test data\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_lr).ravel()\n",
    "\n",
    "# Printing confusion matrix elements\n",
    "print(\"True Negatives test\", tn)\n",
    "print(\"False Positives test:\", fp)\n",
    "print(\"False Negatives test:\", fn)\n",
    "print(\"True Positives test\", tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ea2a0-6b47-48e5-a26f-d3e6f371e332",
   "metadata": {},
   "source": [
    "The odds of logistic regression allow us to understand how the model is working. In particular, an unrealistically high importance is given to Torque and Rotational Speed. This is mainly due to the natural variance in these features, which is especially high when looking only at the failure cases and tends to \"deviate\" the model. However it is reasonable to believe, on the basis of exploratory analysis, that the first four features have a significantly greater relevance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df13ba-1940-4595-ade2-a1f3e9ecf8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "rfc = RandomForestClassifier()\n",
    "xgb = XGBClassifier() \n",
    "clf = [knn,svc,rfc,xgb]\n",
    "clf_str = ['KNN','SVC','RFC','XGB']\n",
    "\n",
    "# Parameter grids for GridSearch\n",
    "knn_params = {'n_neighbors':[1,3,5,8,10]}\n",
    "svc_params = {'C': [1, 10, 100],\n",
    "              'gamma': [0.1,1],\n",
    "              'kernel': ['rbf'],\n",
    "              'probability':[True],\n",
    "              'random_state':[0]}\n",
    "rfc_params = {'n_estimators':[100,300,500,700],\n",
    "              'max_depth':[5,7,10],\n",
    "              'random_state':[0]}\n",
    "xgb_params = {'n_estimators':[300,500,700],\n",
    "              'max_depth':[5,7],\n",
    "              'learning_rate':[0.01,0.1],\n",
    "              'objective':['binary:logistic']}\n",
    "params = pd.Series(data=[knn_params,svc_params,rfc_params,xgb_params],\n",
    "                   index=clf)\n",
    "\n",
    "# Tune hyperparameters with GridSearch (estimated time 8m)\n",
    "print('GridSearch start')\n",
    "fitted_models_binary = []\n",
    "for model, model_name in zip(clf, clf_str):\n",
    "    print('Training '+str(model_name))\n",
    "    fit_model = tune_and_fit(model,X_train,y_train,params[model],'binary')\n",
    "    fitted_models_binary.append(fit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca44e2-d044-4cb1-b92b-865d467909c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation metrics\n",
    "task = 'binary'\n",
    "y_pred_val, cm_dict_val, metrics_val = predict_and_evaluate(\n",
    "    fitted_models_binary,X_val,y_val,clf_str,task)\n",
    "y_pred_test, cm_dict_test, metrics_test = predict_and_evaluate(\n",
    "    fitted_models_binary,X_test,y_test,clf_str,task)\n",
    "\n",
    "# Show Validation Confusion Matrices\n",
    "fig, axs = plt.subplots(ncols=4, figsize=(20,4))\n",
    "fig.suptitle('Validation Set Confusion Matrices')\n",
    "for j, model_name in enumerate(clf_str):\n",
    "    ax = axs[j]\n",
    "    sns.heatmap(ax=ax, data=cm_dict_val[model_name], annot=True,\n",
    "                fmt='d', cmap='Blues', cbar=False)\n",
    "    ax.title.set_text(model_name)\n",
    "    ax.set_xticklabels(cm_labels)\n",
    "    ax.set_yticklabels(cm_labels)\n",
    "plt.show()\n",
    "\n",
    "# Show Test Confusion Matrices\n",
    "fig, axs = plt.subplots(ncols=4, figsize=(20,4))\n",
    "fig.suptitle('Test Set Confusion Matrices')\n",
    "for j, model_name in enumerate(clf_str):\n",
    "    ax = axs[j]\n",
    "    sns.heatmap(ax=ax, data=cm_dict_test[model_name], annot=True,\n",
    "                fmt='d', cmap='Blues', cbar=False)\n",
    "    ax.title.set_text(model_name)\n",
    "    ax.set_xticklabels(cm_labels)\n",
    "    ax.set_yticklabels(cm_labels)\n",
    "plt.show()\n",
    "\n",
    "# Print scores\n",
    "print('')\n",
    "print('Validation scores:', metrics_val, sep='\\n')\n",
    "print('Test scores:', metrics_test, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9fb940-1ad3-4982-8bc3-e244cfe59f12",
   "metadata": {},
   "source": [
    "### RESULT SUMMARY\n",
    "All the selected models obtain similar results on the validation set (except `KNN` and `SVC` which are pretty worse), and it is difficult to determine if one works better than another by looking only at these values. `Performance` did not significantly drop when passing the test set, showing that overfitting was avoided.  I comment on the results of the models by looking at the `confusion matrices` and the `metrics` obtained on the test set: in this way, the formation of a hierarchy between the models used is slightly clearer, as all the metrics relating to a single model are smaller or larger than to the others and the time needed to search for the parameters is comparable, with the only exception of `KNN`. In particular `KNN` obtains the worst performances and XGB the best ones; in the middle we find SVC and RFC which achieve extremely diffrent results also, where RFC is better.\n",
    "\n",
    "### About the parameters:\n",
    "\n",
    "A Gridsearch has been started on the parameters which, looking in the literature, appear to be preponderant for each specific model;\n",
    "The grid values to search for have been defined on the basis of literature and various tests, trying to keep the computational cost of finding the best values moderate.\n",
    "It is interesting to observe that the optimal parameters for `RFC` and `XGB` are the polar opposite: the former prefers to use a few estimators and go into depth while the latter uses more estimators with fewer splits. In any case, to get an idea of which features had greater importance in making the predictions, we report the permutation feature importances in a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331529a5-b265-4028-ac90-0540eac608f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Permutation Feature Importances\n",
    "f2_scorer = make_scorer(fbeta_score, pos_label=1, beta=2)\n",
    "importances = pd.DataFrame()\n",
    "for clf in fitted_models_binary:\n",
    "    result = permutation_importance(clf, X_train,y_train,\n",
    "                                  scoring=f2_scorer,random_state=0)\n",
    "    result_mean = pd.Series(data=result.importances_mean, index=X.columns)\n",
    "    importances = pd.concat(objs=[importances,result_mean],axis=1)\n",
    "importances.columns = clf_str\n",
    "\n",
    "# Barplot of Feature Importances\n",
    "fig, axs = plt.subplots(ncols=4, figsize=(20,4))\n",
    "fig.suptitle('Permutation Feature Importances')\n",
    "for j, name in enumerate(importances.columns):\n",
    "    sns.barplot(ax=axs[j], x=importances.index, y=importances[name].values)\n",
    "    axs[j].tick_params('x',labelrotation=90)\n",
    "    axs[j].set_ylabel('Importances')\n",
    "    axs[j].title.set_text(str(name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742281b1-056f-48cd-b698-c640ee30cdef",
   "metadata": {},
   "source": [
    "### Remarks on Feature importances:\n",
    "\n",
    "air and process temprature  are the features with the lowest significance, also in accordance with what was observed during the exploratory analysis. However, their importance remains strictly positive in each of the cases considered and therefore removing them completely would have led to a decline in prediction performance, not justified by a significant computational gain;\n",
    "\n",
    "Unlike Logistic Regression and Support vector, the models tested place great emphasis on Rotational speed as well as Tool wear, power output and temperature difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3100e3fe-34ad-4d71-87ca-7ae27e7ff832",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, I explored various machine learning models for binary classification in the context of predicting equipment failures in an industrial setting. I trained Logistic Regression, K-Nearest Neighbors (KNN), Support Vector Classifier (SVC), Random Forest Classifier (RFC), and XGBoost Classifier (XGB) models. my analysis focused on understanding model performance under different feature subsets and evaluating their effectiveness on both validation and test datasets.\n",
    "\n",
    "Initially, I trained the models on different subsets of features, including variations based on temperature and power-related variables. Despite observing minor fluctuations in model performance across these feature subsets, all models performed better when trained on the entire dataset compared to reduced feature sets.\n",
    "\n",
    "Subsequently, I evaluated the best-performing model, `Random Forest and XG-boost`, on the validation and test sets. They exhibited robust performance, achieving high accuracy, area under the curve (AUC), and balanced precision and recall scores on both datasets. Confusion matrices provided insights into the model's ability to correctly classify failure and non-failure instances, with relatively low false positive and false negative rates.\n",
    "\n",
    "Additionally, odds ratios derived from the Logistic Regression model shed light on the relative importance of individual features. While certain features such as Torque and Rotational Speed exhibited high odds ratios, suggesting their significant impact on predictions, others like Air and Process Temperature showed lower significance but remained positively associated with the target variable.\n",
    "\n",
    "Furthermore, I employed grid search to optimize hyperparameters for KNN, SVC, RFC, and XGB models. Despite varying optimal parameter configurations, all models demonstrated competitive performance on the test set, indicating effective generalization and mitigating overfitting concerns.\n",
    "\n",
    "In summary, my analysis underscores the suitability of `Random Forest and XG-boost` for the given classification task, with strong performance validated across multiple metrics and datasets. The grid search for hyperparameter optimization provided valuable insights into model parameter preferences, while feature importance analysis highlighted key predictors influencing failure predictions in the industrial context. Overall, the selected models offer promising capabilities for real-world deployment, subject to further validation and fine-tuning as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5556f7-f33f-4cff-ad32-c528e79eb4a0",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e2c69-8bbc-4876-ae5b-c7770a2afe73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
