{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c1efa7-2f53-44c8-bac5-1fa5fabe3009",
   "metadata": {},
   "source": [
    "## Project Description:\n",
    "\n",
    "This notebook focuses on predictive maintenance in industrial settings using machine learning techniques. The objective is to develop a binary classification model capable of predicting machine failures. Leveraging various features such as temperature, rotational speed, torque, and tool wear, the model aims to accurately classify whether a machine is likely to experience failure or not. By employing advanced algorithms and robust evaluation methodologies, the notebook seeks to provide actionable insights for proactive maintenance strategies, ultimately enhancing operational efficiency and reducing downtime in industrial processes.\n",
    "\n",
    "## Project Objective:\n",
    "\n",
    "The primary goal of this notebook is to develop a robust binary classification model for predictive maintenance. The model will leverage historical data on machine performance and failure events to predict whether a machine is likely to fail in the future.\n",
    "\n",
    "Data Preprocessing: Prepare the dataset by cleaning, transforming, and encoding features to ensure compatibility with machine learning algorithms.\n",
    "\n",
    "Feature Engineering: Extract meaningful features and engineer new ones to capture important patterns and relationships in the data, enhancing predictive performance.\n",
    "\n",
    "`Model Training: Implement and fine-tune various machine learning algorithms, including logistic regression, random forest, and gradient boosting, to develop a predictive binary classification model.`\n",
    "\n",
    "`Model Evaluation: Evaluate the performance of the trained models using appropriate metrics such as accuracy, precision, recall, F1 score, and ROC AUC score. Employ cross-validation techniques to ensure robustness and generalization.`\n",
    "\n",
    "Model Deployment: Deploy the best-performing model to production or integrate it into existing systems for real-time prediction of machine failures. Provide recommendations for proactive maintenance actions based on model insights.\n",
    "\n",
    "By achieving these objectives, the notebook aims to empower industrial stakeholders with predictive analytics capabilities, enabling them to anticipate and mitigate potential machine failures, optimize maintenance schedules, and improve overall operational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e943075b-1094-477e-9b3f-9beadecd33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, f1_score, fbeta_score, recall_score, precision_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f8d7ca5-45f1-40d5-8938-9399690b4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(r'C:\\Users\\USER\\Documents\\Python Scripts\\Machine learning\\Neural networks\\Predictive Maintenance\\predictive-maintenance-supervised-learning\\scripts')\n",
    "#   # Add the directory containing training and evaluation scripts to Python path\n",
    "\n",
    "# from model_training import fit_models, tune_and_fit\n",
    "# from  model_evaluation import eval_preds,  predict_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc348df9-7cfb-4cab-a560-d40560e07e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data for model training and evaluation(binary)\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Load resampled data for Machine Failure\n",
    "X_res_mf, y_res_mf = joblib.load(r'C:\\Users\\USER\\Documents\\Python Scripts\\Machine learning\\Neural networks\\Predictive Maintenance\\predictive-maintenance-supervised-learning\\data\\resampled_machine_failure.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74984273-f388-485e-b571-629fd5c3e203",
   "metadata": {},
   "source": [
    "## Binary task ¶\n",
    "\n",
    "###  Preliminaries \n",
    "\n",
    "The goal of this section is to find the best model for binary classification of the dataset to predict whether or not there will be Machine Failure. Classification algorithms are part of data mining and use supervised machine learning methods to make predictions about data. In particular, a set of data already divided (”labeled”) into two or more classes of belonging is provided as input thanks to which a classification model is created, which will than be used on new (”unlabeled”) data to assign them to the appropriate class. The starting dataset is usually divided into three groups: the training dataset, i.e. the sample of data used to fit the model, the validation dataset, i.e. the sample of data used to provide an evaluation of a model fit on the training dataset while tuning model hyperparameters and the test dataset, which has the purpose of testing the model. At the beginning of a project a data scientist must make this division and the common ratios used are:\n",
    "\n",
    "70% train, 15% val, 15% test.\n",
    "\n",
    "80% train, 10% val, 10% test.\n",
    "\n",
    "60% train, 20% val, 20% test.\n",
    "\n",
    "In this project we use the ratio (80/10/10) for the split because we test the model for all of these strategies and find that it is the best one. The classification techniques we choose to implement are the following:\n",
    "\n",
    "- Logistic Regression: it estimates the probability of a dependent variable as a function of independent variables. The dependent variable is the output that we are trying to predict while the independent variables or explanatory variables are the factors that we feel could influence the output. For its simplicity and interpretability, we decide to use Logistic Regression as a Benchmark model, a basic model that represents the starting point\n",
    "for comparing the results obtained from other models.\n",
    "\n",
    "- K-nearest neighbors (K-NN): algorithm based on the calculation of the distance between the elements of the dataset. Data is assigned to a certain class if close enough to the other data of the same class. Parameter K represents the number of neighboring data taken into account when assigning classes.\n",
    "\n",
    "- Support Vector Machine: its aim is to find a hyperplane in an N-dimensional space (N—the number of features) that distinctly classifies the data points while maximizing the margin distance, i.e. the distance between data points of both classes.\n",
    "Random Forest: it uses ensemble learning, which is a technique that combines many classifiers to provide solutions to complex problems. Random Forest uses bagging technique: it constructs a multitude of decision trees in parallel, all with the same importance, and the output is the class selected by most trees.\n",
    "\n",
    "- XGBoost: is a gradient-boosted decision tree (GBDT) machine learning library. A Gradient Boosting Decision Tree (GBDT) is a decision tree ensemble learning algorithm similar to Random Forest, from which differs because it uses a boosting technique: it iteratively trains an ensemble of shallow decision trees, with each iteration using the error residuals of the previous model to fit the next model. The final prediction is a weighted sum of all of the tree predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64dc8032-38bc-4a4e-a505-ebf639a1f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-validation-test split\n",
    "X, y = X_res_mf, y_res_mf\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.11, stratify=y_trainval, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262e3f1-22a8-498c-9ef1-ca1f1ba79880",
   "metadata": {},
   "source": [
    "### Feature selection attempts \n",
    "\n",
    "Before going into the training of the models just mentioned we try to perform feature selection, exploiting the considerations  made about the correlation heatmap and the exploratory data analysis: just to remind, it was noticed that the features `\"Process temperature\"` and `\"Air temperature\"` are positively correlated, and `\"Torque\"` and `\"Rotational speed\"` are negatively correlated. From the feature selection we see from the information scores that the product between \"Torque\" and \"Rotational speed\" has more importance than them individually and same can be said about the importance of the product and difference of `\"Process temperature\"` and `\"Air temperature\"` compared to the individual features . For these reasons, completely deleting these columns seems to be a bad choice because important information can be lost but at the same time it is reasonable to see what happens if we combine them taken by pairs. Therefore we proceed to compare the results obtained by fitting the classification models without tuning any parameter on the following datasets:\n",
    "\n",
    "- The original one (without new features)\r",
    "- Tthe one obtained by removing the \"Process temperature\" and \"Air temperature\" columns, replacing them with a column of their produc and differencet\n",
    "- T\n",
    "the one obtained by removing \"Torque\" and \"Rotational speed\", replacing them with a column of their product- Ca comation of ine the previous operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e7e919c-1c30-4932-b2a0-2840d447cc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air temperature _K_</th>\n",
       "      <th>Process temperature _K_</th>\n",
       "      <th>Rotational speed _rpm_</th>\n",
       "      <th>Torque _Nm_</th>\n",
       "      <th>Tool wear _min_</th>\n",
       "      <th>temp_product</th>\n",
       "      <th>temp_difference</th>\n",
       "      <th>power_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>1.198103</td>\n",
       "      <td>0.738714</td>\n",
       "      <td>1.901342</td>\n",
       "      <td>-1.553133</td>\n",
       "      <td>0.755412</td>\n",
       "      <td>1.037842</td>\n",
       "      <td>1.298989</td>\n",
       "      <td>-1.364125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>-1.301338</td>\n",
       "      <td>-1.283370</td>\n",
       "      <td>1.171143</td>\n",
       "      <td>-1.412659</td>\n",
       "      <td>-1.569952</td>\n",
       "      <td>-1.332262</td>\n",
       "      <td>-0.698269</td>\n",
       "      <td>-1.438805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-0.951417</td>\n",
       "      <td>-1.215968</td>\n",
       "      <td>-1.097490</td>\n",
       "      <td>0.814846</td>\n",
       "      <td>-0.847204</td>\n",
       "      <td>-1.094564</td>\n",
       "      <td>-0.099092</td>\n",
       "      <td>0.450633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>1.148114</td>\n",
       "      <td>0.738714</td>\n",
       "      <td>-0.924695</td>\n",
       "      <td>1.306503</td>\n",
       "      <td>1.148210</td>\n",
       "      <td>1.007718</td>\n",
       "      <td>1.199126</td>\n",
       "      <td>1.257284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>1.318212</td>\n",
       "      <td>0.603908</td>\n",
       "      <td>-1.145407</td>\n",
       "      <td>1.133277</td>\n",
       "      <td>-1.097286</td>\n",
       "      <td>1.051612</td>\n",
       "      <td>1.738657</td>\n",
       "      <td>0.821230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>0.362873</td>\n",
       "      <td>0.264788</td>\n",
       "      <td>0.329172</td>\n",
       "      <td>-0.714577</td>\n",
       "      <td>1.658028</td>\n",
       "      <td>0.329803</td>\n",
       "      <td>0.332607</td>\n",
       "      <td>-0.755922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6922</th>\n",
       "      <td>0.348293</td>\n",
       "      <td>0.873520</td>\n",
       "      <td>-0.289255</td>\n",
       "      <td>-0.017960</td>\n",
       "      <td>-0.910051</td>\n",
       "      <td>0.583972</td>\n",
       "      <td>-0.598406</td>\n",
       "      <td>-0.076181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>-0.751461</td>\n",
       "      <td>-1.418176</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>-0.690225</td>\n",
       "      <td>0.598293</td>\n",
       "      <td>-1.061903</td>\n",
       "      <td>0.599948</td>\n",
       "      <td>-0.556964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>-0.501517</td>\n",
       "      <td>-0.878954</td>\n",
       "      <td>-0.501068</td>\n",
       "      <td>-0.108264</td>\n",
       "      <td>-1.412833</td>\n",
       "      <td>-0.681217</td>\n",
       "      <td>0.300360</td>\n",
       "      <td>-0.352612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>1.448047</td>\n",
       "      <td>0.671311</td>\n",
       "      <td>1.566900</td>\n",
       "      <td>-1.543099</td>\n",
       "      <td>0.315478</td>\n",
       "      <td>1.159131</td>\n",
       "      <td>1.898166</td>\n",
       "      <td>-1.490539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8206 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Air temperature _K_  Process temperature _K_  Rotational speed _rpm_  \\\n",
       "3829              1.198103                 0.738714                1.901342   \n",
       "335              -1.301338                -1.283370                1.171143   \n",
       "182              -0.951417                -1.215968               -1.097490   \n",
       "3757              1.148114                 0.738714               -0.924695   \n",
       "10002             1.318212                 0.603908               -1.145407   \n",
       "...                    ...                      ...                     ...   \n",
       "10013             0.362873                 0.264788                0.329172   \n",
       "6922              0.348293                 0.873520               -0.289255   \n",
       "1737             -0.751461                -1.418176                0.563573   \n",
       "2591             -0.501517                -0.878954               -0.501068   \n",
       "4594              1.448047                 0.671311                1.566900   \n",
       "\n",
       "       Torque _Nm_  Tool wear _min_  temp_product  temp_difference  \\\n",
       "3829     -1.553133         0.755412      1.037842         1.298989   \n",
       "335      -1.412659        -1.569952     -1.332262        -0.698269   \n",
       "182       0.814846        -0.847204     -1.094564        -0.099092   \n",
       "3757      1.306503         1.148210      1.007718         1.199126   \n",
       "10002     1.133277        -1.097286      1.051612         1.738657   \n",
       "...            ...              ...           ...              ...   \n",
       "10013    -0.714577         1.658028      0.329803         0.332607   \n",
       "6922     -0.017960        -0.910051      0.583972        -0.598406   \n",
       "1737     -0.690225         0.598293     -1.061903         0.599948   \n",
       "2591     -0.108264        -1.412833     -0.681217         0.300360   \n",
       "4594     -1.543099         0.315478      1.159131         1.898166   \n",
       "\n",
       "       power_output  \n",
       "3829      -1.364125  \n",
       "335       -1.438805  \n",
       "182        0.450633  \n",
       "3757       1.257284  \n",
       "10002      0.821230  \n",
       "...             ...  \n",
       "10013     -0.755922  \n",
       "6922      -0.076181  \n",
       "1737      -0.556964  \n",
       "2591      -0.352612  \n",
       "4594      -1.490539  \n",
       "\n",
       "[8206 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81b3f8ac-7b07-4618-8b33-a3ad77557e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preds(model, X, y_true, y_pred, task):\n",
    "    if task == 'binary':\n",
    "        # y_true = y_true['Machine failure']\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        proba = model.predict_proba(X)[:,1]\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, proba)\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "        f2 = fbeta_score(y_true, y_pred, pos_label=1, beta=2)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "    elif task == 'multi_class':\n",
    "        # y_true = y_true['Failure Type']\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        proba = model.predict_proba(X)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, proba, multi_class='ovr', average='weighted')\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        f2 = fbeta_score(y_true, y_pred, beta=2, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "        precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    metrics = pd.Series(data={'ACC':acc, 'AUC':auc, 'F1':f1, 'F2':f2, 'Recall': recall, 'Precision': precision})\n",
    "    metrics = round(metrics,3)\n",
    "    return cm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b68e39d-d5c9-42ab-966f-be1dd7156e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models(clf, clf_str, X_train, X_val, y_train, y_val):\n",
    "    metrics = pd.DataFrame(columns=clf_str)\n",
    "    for model, model_name in zip(clf, clf_str):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        metrics[model_name] = eval_preds(model, X_val, y_val, y_val_pred, 'binary')[1]\n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5e737e4-cc44-44ff-95ff-aa32a5b1d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over column names\n",
    "for column_name in X_train.columns:\n",
    "    # Check if the column name contains any of the restricted characters\n",
    "    if '[' in column_name or ']' in column_name or '<' in column_name:\n",
    "        print(f\"Column name '{column_name}' contains invalid characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3b592-e522-4e7c-a7b1-e2ee470f4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC(probability=True)\n",
    "rfc = RandomForestClassifier()\n",
    "xgb = XGBClassifier() \n",
    "\n",
    "clf = [lr,knn,svc,rfc,xgb]\n",
    "clf_str = ['LR','KNN','SVC','RFC','XGB'] \n",
    "\n",
    "# Fit on raw train\n",
    "XX_train = X_train.drop(columns=['temp_product','temp_difference','power_output'])\n",
    "XX_val = X_val.drop(columns=['temp_product','temp_difference','power_output'])\n",
    "metrics_0 = fit_models(clf, clf_str, XX_train, XX_val, y_train, y_val)\n",
    "\n",
    "# Fit on temperature product and difference train\n",
    "XX_train = X_train.drop(columns=['Process temperature _K_','Air temperature _K_','power_output'])\n",
    "XX_val = X_val.drop(columns=['Process temperature _K_','Air temperature _K_','power_output'])\n",
    "metrics_1 = fit_models(clf, clf_str, XX_train, XX_val, y_train, y_val)\n",
    "\n",
    "# Fit on power product train\n",
    "XX_train = X_train.drop(columns=['Rotational speed _rpm_','Torque _Nm_','temp_product','temp_difference'])\n",
    "XX_val = X_val.drop(columns=['Rotational speed _rpm_','Torque _Nm_','temp_product','temp_difference'])\n",
    "metrics_2 = fit_models(clf, clf_str, XX_train, XX_val, y_train, y_val)\n",
    "\n",
    "# Fit on both products train\n",
    "XX_train = X_train.drop(columns=['Process temperature _K_','Air temperature _K_','Rotational speed _rpm_','Torque _Nm_'])\n",
    "XX_val = X_val.drop(columns=['Process temperature _K_','Air temperature _K_','Rotational speed _rpm_','Torque _Nm_'])\n",
    "metrics_3 = fit_models(clf, clf_str, XX_train, XX_val, y_train, y_val)\n",
    "\n",
    "# classification metrics barplot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(18,8))\n",
    "fig.suptitle('Classification metrics')\n",
    "for j, model in enumerate(clf_str):\n",
    "    ax = axs[j//3,j-3*(j//3)]\n",
    "    model_metrics = pd.DataFrame(data=[metrics_0[model],metrics_1[model],metrics_2[model],metrics_3[model]])\n",
    "    model_metrics.index = ['Original','Temperature','Power','Both']\n",
    "    model_metrics.transpose().plot(ax=ax, kind='bar', rot=0, )\n",
    "    ax.title.set_text(model)\n",
    "    ax.get_legend().remove()\n",
    "fig.subplots_adjust(top=0.9, left=0.1, right=0.9, bottom=0.12)\n",
    "axs.flatten()[-2].legend(title='Dataset', loc='upper center',\n",
    "                         bbox_to_anchor=(0.5, -0.12), ncol=4, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a811c8-6369-4a41-b359-ae44923e92a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
